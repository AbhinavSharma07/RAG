# ğŸ” Advanced Full-Stack RAG (Retrieval-Augmented Generation) Application

This is a production-grade, full-stack RAG application that allows users to upload documents (PDFs), ask natural language questions, and get answers grounded in those documents â€” powered by OpenAI, FAISS, ElasticSearch, and a React-based chat UI.

---

## ğŸš€ Features

- ğŸ“„ PDF document upload and ingestion
- ğŸ§  OpenAI Embeddings (`text-embedding-3-small`)
- ğŸ” Hybrid Retrieval:
  - ğŸ”¹ Vector similarity search (FAISS)
  - ğŸ”¹ Keyword/BM25 search (ElasticSearch)
- ğŸ§© Chunk-level citations in answers
- ğŸ’¬ Chat UI with token-by-token streaming (WebSocket)
- ğŸ³ Fully Dockerized: backend, frontend, ElasticSearch, Grafana
- ğŸ“Š Monitoring with Prometheus and Grafana
- ğŸ§ª Ready for CI/CD, local or cloud deployment
- ğŸ” Environment-variable based configuration
- ğŸ–¥ï¸ Optional local LLM support (via Ollama)

---

## ğŸ› ï¸ Tech Stack

| Layer      | Tech                             |
|------------|----------------------------------|
| Backend    | FastAPI + Python                 |
| Embeddings | OpenAI API (fallback: HF models) |
| Retrieval  | FAISS + ElasticSearch (BM25)     |
| Streaming  | WebSockets + Token Streaming     |
| DevOps     | Docker, Docker Compose           |
| Monitoring | Prometheus + Grafana             |

---

## ğŸ³ Build and run with Docker

```bash
docker-compose up --build
```

---

Frontend: http://localhost:3000  
Backend: http://localhost:8000  
ElasticSearch: http://localhost:9200  
Grafana: http://localhost:3001 (login: admin / admin)
